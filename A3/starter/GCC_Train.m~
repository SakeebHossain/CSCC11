%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CSC C11 - Assignment 3 - Classification by Gaussian Class Conditionals
%
% In this function, you will implement the code that trains the GCC model
% for the input dataset. 
%
% Inputs:
%
% train_data   -  The training data set  (one input sample per row)
% train_labels -  Labels for the training data set
% K            -  Number of components in the GCC model
%
% Returns:
%
% centers      - Each row is the center of a Gaussian in the GCC model
% covs         - A NxNxK matrix with K, NxN covariance matrices
% ais          - Mixture proportions
%
% F.J.E. Nov, 2017
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

function [centers,covs,ais]=GCC_train(train_data,train_labels,K);

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% COMPLETE THIS TEXT BOX:
%
% 1) Student Name: Ahnaf Sakeeb Hossain
% 2) Student Name:		
%
% 1) Student number: 1001537483
% 2) Student number:
% 
% 1) UtorID hossa171
% 2) UtorID
% 
% We hereby certify that the work contained here is our own
% Ahnaf Sakeeb Hossain
% ____________________             _____________________
% (sign with your name)            (sign with your name)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% TO DO: Complete the function to learn the parameters of the model
%        this should be fairly similar to your GMMs from A2!
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Remember: the whole idea behind GMM is to learn the mean and covariance
% of the Gaussians that maximize the probability of the data. 
% Since we have input data, we can use these to initialize those parameters
% directly.

N=size(train_data, 1);
D=size(train_data, 2);

% coefficients: for each label, count how many instances we have of that
% label and just divide by the total number of data points.
labels = unique(train_labels);
num_unique_labels = size(labels, 1);

labels_count = zeros(num_unique_labels,1);

for i=1:size(labels, 1)
  labels_count(i) = nnz(train_labels==labels(i));
end

ais = labels_count ./ N;

% centers: take an average of all data points of your label
center_totals = zeros(num_unique_labels,D);

for i=1:N
  data_point = train_data(i,:);
  data_label = train_labels(i)+1;
  center_totals(data_label, :) = center_totals(data_label, :) + data_point;
end

centers = center_totals ./ labels_count;

% covariances: go through all data points for your label and calcutate the
% distance matrix. Sum them all up and divide them by number of points for your label.

% cov_sum = zeros([D D num_unique_labels]);
% for i=1:N
%   disp(i);
%   data_point = train_data(i,:);  % grab data point
%   data_label = train_labels(i)+1;  % get that data point's label
%   center = centers(data_label, :); % get the center for that data point
%   cov=(data_point - center)*(data_point - center)'; % make a covariance matrix to store this rounds calculation
%   cov_sum(:,:,data_label) = cov_sum(:,:,data_label) + cov; % add to rest of covs for that label
%   
% end

covs = zeros([D D num_unique_labels]);
for i=1:num_unique_labels

  % init a dxd
  cov_i = zeros(D,D);
  % get all data points with label i
  data_i = train_data(train_labels==(labels(i)+1));
  % subtract their mean from them all
  data_i = data_i - centers(i,:);
  % for each data point in the label, compute covariance
  for j=1:size(data_i,1)
      disp(j);
      cov_ = (data_i(j,:) - centers(i,:))*(data_i(j,:) - centers(i,:))';
      cov_i = cov_i + cov_;
  end
  covs(:,:,i) = cov_i ;
end
